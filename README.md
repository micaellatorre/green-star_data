# **Green Star Data**  

**Green Star Data** es un repositorio dedicado al desarrollo de modelos de **machine learning** para la predicciÃ³n del rendimiento en cultivos de **cannabis medicinal**. Forma parte del ecosistema de [**Green Star**](https://www.green-star.app), una aplicaciÃ³n diseÃ±ada para la recopilaciÃ³n y anÃ¡lisis de datos de ciclos de cultivo, con el objetivo de ofrecer informaciÃ³n valiosa a cultivadores y facilitar la toma de decisiones basadas en datos.  

Este proyecto se centra en la creaciÃ³n de un **dataset estructurado** a partir de datos histÃ³ricos y de cultivadores reales, aplicando tÃ©cnicas avanzadas de **preprocesamiento**, **oversampling** y **modelado predictivo** para abordar la tarea de clasificaciÃ³n del rendimiento.  

## **ğŸ“ Estructura del Proyecto**

El repositorio estÃ¡ organizado en los siguientes directorios clave:  

green-star_data/<br/>
â”‚<br/>
â”œâ”€â”€ data/<br/>
â”‚&emsp;â”œâ”€â”€ history/                  &emsp;# Historial de datasets utilizados<br/>
â”‚&emsp;â””â”€â”€ preprocessed/             &emsp;# Historial de datasets preprocesados<br/>
â”‚<br/>
â”œâ”€â”€ scripts/<br/>
â”‚&emsp;â”œâ”€â”€ preprocessing/                &emsp;# Limpieza y preprocesamiento del dataset<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ user_processing.py        &emsp;# Identificador Ãºnico autoincremental del usuario<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ tipo_de_simulacion.py     &emsp;# Numerar el tipo de simulaciÃ³n<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ cultivador_rating.py      &emsp;# CÃ¡lculo del puntaje del cultivador<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ geolocation_processing.py &emsp;# Desgloce de lat y lon<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ dli_calc.py               &emsp;# CÃ¡lculo de DLI por etapa del cultivo<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ var_coding.py             &emsp;# CodificaciÃ³n de variables categÃ³ricas<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ dates_transform.py        &emsp;# TransformaciÃ³n de fechas a caracterÃ­sticas numÃ©ricas<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ categorize_yield.py       &emsp;# Categorizar la variable objetivo<br/>
â”‚&emsp;â”‚&emsp;â””â”€â”€ main.py<br/>
â”‚&emsp;â”‚<br/>
â”‚&emsp;â”œâ”€â”€ oversampling/             &emsp;# TÃ©cnicas de oversampling<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ random_oversampling.py&emsp;# Random Oversampling sencillo<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ smote.py              &emsp;# SMOTE (Synthetic Minority Oversampling Technique)<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ adasyn.py             &emsp;# ADASYN (Adaptive Synthetic Sampling)<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ cluster_based.py      &emsp;# Cluster-Based Oversampling<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ knn_interpolation.py  &emsp;# KNN Interpolation<br/>
â”‚&emsp;â”‚&emsp;â””â”€â”€ main.py<br/>
â”‚&emsp;â”‚<br/>
â”‚&emsp;â”œâ”€â”€ training/                 &emsp;# Modelos de Entrenamiento<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ linear_regression.py  &emsp;# Entrenamiento con regresiÃ³n lineal<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ random_forest.py      &emsp;# Entrenamiento con Random Forest<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ xgboost.py            &emsp;# Entrenamiento con XGBoost<br/>
â”‚&emsp;â”‚&emsp;â””â”€â”€ main.py<br/>
â”‚&emsp;â”‚<br/>
â”‚&emsp;â””â”€â”€ analysis/                     &emsp;# Scripts de evaluaciÃ³n<br/>
â”‚&emsp;&nbsp;&emsp;â”œâ”€â”€ comparative_analysis.py   &emsp;# ComparaciÃ³n de mÃ©tricas entre tÃ©cnicas de oversampling<br/>
â”‚&emsp;&nbsp;&emsp;â”œâ”€â”€ feature_importance.py     &emsp;# EvaluaciÃ³n de los campos mÃ¡s relevantes para RF y XGB<br/>
â”‚&emsp;&nbsp;&emsp;â”œâ”€â”€ svm_feature_importance.py &emsp;# EvaluaciÃ³n de los campos mÃ¡s relevantes para SVM<br/>
â”‚&emsp;&nbsp;&emsp;â”œâ”€â”€ model_evaluation.py       &emsp;# EvaluaciÃ³n de mÃ©tricas y matrices de confusiÃ³n<br/>
â”‚&emsp;&nbsp;&emsp;â””â”€â”€ visualization.py          &emsp;# Ploteo de las mÃ©tricas comparativas<br/>
â”‚<br/>
â”œâ”€â”€ outputs/<br/>
â”‚&emsp;â”œâ”€â”€ oversampled/              &emsp;# Resultados para cada tÃ©cnica de oversampling<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ random/<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ smote/<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ adasyn/<br/>
â”‚&emsp;â”‚&emsp;â””â”€â”€ cluster_based/<br/>
â”‚&emsp;â”‚<br/>
â”‚&emsp;â”œâ”€â”€ trained/                  &emsp;# Resultados del entrenamiento para cada tÃ©cnica<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ random_forest/<br/>
â”‚&emsp;â”‚&emsp;â”œâ”€â”€ svm/<br/>
â”‚&emsp;â”‚&emsp;â””â”€â”€ xgboost/<br/>
â”‚&emsp;â”‚<br/>
â”‚&emsp;â”œâ”€â”€ figures/                  &emsp;# GrÃ¡ficos generados<br/>
â”‚&emsp;â””â”€â”€ metrics/                  &emsp;# MÃ©tricas de evaluaciÃ³n<br/>
â”‚<br/>
â””â”€â”€ README.md                     &emsp;# DescripciÃ³n del proyecto<br/>

## **ğŸ”¬ TÃ©cnicas Implementadas**  

### **ğŸ“Œ Preprocesamiento de Datos**  
âœ”ï¸ NormalizaciÃ³n y transformaciÃ³n de variables  
âœ”ï¸ EliminaciÃ³n de valores atÃ­picos  
âœ”ï¸ CodificaciÃ³n de variables categÃ³ricas  

### **ğŸ“Œ Oversampling**  
âœ”ï¸ **Random Oversampling**  
âœ”ï¸ **SMOTE (Synthetic Minority Oversampling Technique)**  
âœ”ï¸ **ADASYN (Adaptive Synthetic Sampling)**  
âœ”ï¸ **Cluster-Based Oversampling**  
âœ”ï¸ **KNN Interpolation**

### **ğŸ“Œ Modelos de Machine Learning**  
âœ”ï¸ **Random Forest**  
âœ”ï¸ **Support Vector Machine (SVM)**  
âœ”ï¸ **XGBoost**  

### **ğŸ“Œ EvaluaciÃ³n y ComparaciÃ³n**  
âœ”ï¸ **AnÃ¡lisis de importancia de variables**  
âœ”ï¸ **Matrices de confusiÃ³n**  
âœ”ï¸ **MÃ©tricas de rendimiento**: Accuracy, Precision, Recall, F1-Score  
